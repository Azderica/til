---
sidebar_position: 10
---

들어가기 앞서서 데이터를 저장하고 처리하는 시스템은 크게 두 분류로 나눠집니다.

- 레코드 시스템, 믿을 수 있는 데이터 버전을 저장합니다. 정규화를 거쳐 정확하게 한번 표현됩니다.
- 파생 데이터 시스템, 다른 시스템에 존재하는 데이터를 가져와 특정 방식으로 변환하고 처리한 결과입니다.

파생 데이터는 기존 데이터를 복제한다는 의미에서 중복(redundant)이며, 읽기 질의 성능을 높이는데 필수적입니다. 파생 데이터는 대개 비정규화 과정을 통해 생성합니다.

# 10. 일괄 처리

- 앞 장에서는 **요청(request), 응답(response), 질의(query), 결과(result)** 에 대해 다뤘습니다.
- **온라인 시스템**에서는 사용자의 **응답 시간 단축**에 많은 노력을 합니다.
- 시스템을 세가지 유형으로 분리하면 다음과 같습니다.
  - **서비스(온라인 시스템)** , 서비스는 클라이언트로부터 요청이나 지시가 올때까지 기다립니다.
  - **일괄 처리 시스템(오프라인 시스템)** , 매우 큰 입력의 데이터를 받아 데이터를 처리하는 작업을 수행하고 결과 데이터를 생산합니다.
  - **스트림 처리 시스템(준실시간 시스템)** , 온라인과 오프라인 사이의 어딘가에 위치하기에 준실시간 처리라고 부릅니다. 일처리 작업은 정해진 크기의 입력 데이터를 대상으로 작동하지만 스트림 처리는 입력 이벤트가 발생한 직후 바로 작동합니다.
- 일괄 처리는 신뢰할 수 있고 확장 가능하며 유지보수하기 쉬운 애플리케이션을 구축하는 데 중요한 구성요소 입니다.

<br/>

## 유닉스 도구로 일괄 처리하기

### 단순 로그 분석

다양한 도구를 통해서 트래픽에 대한 보고설를 생성할 수 있습니다.

```shell
cat /var/log/nginx/access.log |
  awk '{print $7} |
  sort |
  uniq -c |
  sort -r -n |
  head -n 5
```

> > 로그를 읽고, 공백으로 분리된 줄의 7번째 필드만 출력하고, 요청 URL을 정렬하고, 중복을 제거하고,...

> Tip. 개발하면서 로그 분석한거 이야기 주기.

- 이러한 방식은 상당히 강력합니다.

#### 연쇄 명령 대 맞춤형 프로그램

```ruby
counts = Hash.new(0)
File.open('/var/log/nginx/access.log') do |file|
  file.each do |line|
    url = line.split[6]
    counts[url] += 1
  end
end
top5 = counts.map(|url, count| [count, url] }.sort.reverse[0...5]
top.each{|count,url|puts "${count} ${url}"}
```

- 표면적인 문법의 차이를 빼고 두가지 방법은 실행 흐름이 크게 다릅니다.

#### 정렬 대 인메모리 집계

- 루비 스크립트는 URL 해시 테이블을 메모리에 유지합니다.
- 유닉스 파이프라인 예제는 이러한 해시 테이블이 없습니다.

허용 메모리보다 작업 세트가 크다면 정렬 접근법을 사용하는 것이 중요합니다.

### 유닉스 철학

유닉스 철학은 다음과 같습니다.

- 각 프로그램이 한 가지 일만 하도록 작성합니다.
- 모든 프로그램의 출력은 아직 알려지지 않은 다른 프로그램의 입력으로 쓰일 수 있다고 생각하라.
- 소프트웨어를 빠르게 써볼 수 있게 설계하고 구축하라.
- 프로그래밍 작업을 줄이려면 미숙한 도움보단 도구를 사용하라.

bash나 shell을 통해 데이터 처리 작업을 쉽게 구성할 수 있습니다.

#### 동일 인터페이스

- 어떤 프로그램의 출력을 다른 프로그램의 입력으로 쓰고자 한다면 이들 프로그램은 같은 데이터 형식을 사용해야 합니다.
- 즉, 특정 프로그램이 다른 **어떤** 프로그램과도 연결 가능하려면 프로그램 **모두**가 같은 입출력 인터페이스를 사용해야 한다는 의미입니다.
- 동일한 데이터 모델인 데이터베이스 간에도 한쪽에서 다른 쪽으로 데이터를 옮기는 게 쉽지 않습니다. 이처럼 데이터가 발칸화되는 이유는 유닉스 도구와 같은 통합이 부족했기 때문입니다.

#### 로직과 연결의 분리

- 유닉스 도구의 다른 특징 중 하나는 표준 입력(stidn)과 표준 출력(stdout)을 사용한다는 점입니다.
- 이러한 경우와 같이 입력이 어디서부터 들어오는지, 출력이 어디로 나가는지 신경을 쓰거나 알 필요가 없습니다.
  - 이러한 형태를 **느슨한 결합(loose coupling)** , **지연 바인딩(late binding)**, 또는 **제어 반전(inversion of control)** 이라고 합니다.

#### 투명성과 실험

- 유닉스 도구가 성공적인 이유 중 하나는 진행 사항을 파악하기가 상당히 쉽습니다.
  - 유닉스 명령에 들어가는 입력 파일은 일반적으로 불변으로 처리됩니다.
  - 어느 시점이든 파이프라인을 중단하고 출력을 파이프를 통해 less로 보내 원하는 형태의 출력이 나오는지 확인할 수 있습니다.
  - 특정 파이프라인 단계의 출력을 파일에 쓰고 그 파일의 다음 단계의 입력으로 사용할 수 있습니다.

유닉스 도구는 일부 불친절하지만 단순하고 유용하빈다. 이러한 가장 큰 제약은 단일 장비에서만 실행되며 이러한 이유로 하둡 같은 도구가 필요합니다.

<br/>

## 맵리듀스와 분산 파일 시스템

- 맵리듀스는 유닉스 도구와 비슷한 면이 있지만 수천 대의 장비로 **분산**해서 실행이 가능하다는 점에서 차이가 있습니다.
- 유닉스 도구와 마찬가지로 맵리듀스 작업은 입력을 수정하지 않기 때문에 출력을 생산하는 것 외에 다른 부수 효과는 없습니다.
- 유닉스 도구는 stdin과 stdout을 사용하는데, 맵리듀스 작업은 분산 파일 시스템상의 파일을 입력과 출력으로 사용하빈다. 이를 **HDFS(Hadoop Distributed File System)** 이라고 합니다.
- HDFS는 **비공유** 원칙을 기반으로 하며, **NAS(Network Attached Storage)** 나 **SAN(Storage Area Network)** 아키텍처에서 사용하는 공유 디스크 방식과는 반대입니다.
- HDFS는 각 장비에서 실행되는 데몬 프로세스로 구성됩니다.
  - 데몬 프로세스는 다른 노드가 해당 장비에 저장된 파일에 접근 가능하게끔 네트워크 서비스를 제공합니다.
  - **네임노드(NameNode)** 라고 부르는 중앙 서버는 특정 파일 블록이 어떤 장비에 저장됐는지 추적합니다.
  - 즉 , HDFS는 개념적으로는 매우 큰 하나의 파일 시스템이고 데몬이 실행중인 모든 장비의 디스크를 활용할 수 있습니다.
- 장비가 죽거나 디스크가 실패하는 경우에 대비하기 위해 파일 블록은 여러 장비에 복제됩니다.
- HDFS는 확장성이 뛰어납니다.

### 맵리듀스 작업 실행하기

- 맵리듀스는 HDFS와 같은 분산 파일 시스템 위에서 대용량 데이터셋을 처리하는 코드를 작성하는 프로그래밍 프레임워크입니다.
- 맵리듀스 작업 하나는 4가지 단계로 구성됩니다.
  - 1단계 : 파일을 나누어 레코드를 만드는 데 입력 형식 파서를 씁니다.
  - 2단계 : 맵(Map)
  - 3단계 : 정렬 단계
  - 4단계 : 리듀스
- 맵리듀스 작업을 생성하려면 다음과 같이 동작하는 매퍼와 리듀서라는 콜백 함수를 구현해야 합니다.
  - 매퍼(Mapper) : 매퍼는 모든 입력 레코드마다 한 번씩만 호출됩니다.
  - 리듀서(Reducer) : 맵리듀스 프레임워크는 매퍼가 생성한 키- 값 쌍을 받아 같은 키를 가진 레코드를 모으고 해당 값의 집합을 반복해 리듀서 함수를 호출합니다.
- 매퍼는 정렬에 적합한 형태로 데이터를 준비하는 역할을 하고, 리듀서는 정렬된 데이터를 가공하는 역할을 합니다.

#### 맵리듀스의 분산 실행

- 유닉스 명령어 파이프라인과 가장 큰 차이점은 맵리듀스가 병렬로 수행하는 코드를 직접 작성하지 않고도 여러 장비에서 동시에 처리가 가능합니다.
  - 매퍼와 리듀서는 한 번에 하나의 레코드만 처리하고 입력이 어디서, 출력이 어디로 가는지 신경쓰지 않습니다.
- 분산 연사에서 매퍼와 리듀서로 표준 유닉스 도구를 사용하는 것도 가능하빈다.
- 하둡 맵리듀스 작업에서 데이터플로를 보여줍니다. 맵리듀스 작업의 병렬 실행은 파티셔닝을 기반으로 합니다.
- RAM과 CPU에 여유가 있다면 맵리듀스 스케줄러가 입력 파일이 있는 장비에서 작업을 수행하는 것이 좋은 데 이 원리를 **데이터 가까이에서 연산하기**라고 합니다.
- 대표적인 예시로, 자바 프로그램을 예로 들면 JAR 파일을 복사한 후 각 장비에서 매퍼 태스크가 시작됩니다. 입력 파일을 읽기 시작하면 입력 파일에서 한 번에 레코드 하나씩 읽어 매퍼 콜백 함수로 전달합니다.
- 리듀서 측 연산도 파티셔닝됩니다. (태스크 수는 사용자가 설정합니다.)
- 키-값 쌍은 반드시 정렬돼야 하지만 대개 데이터셋이 매우 크기 때문에 단게를 나눠서 정렬을 수행합니다.
- 매퍼가 입력 파일을 읽어서 정렬된 출력 파일을 기록하기를 완료하면 맴 리듀스 스케줄러는 그 매퍼에서 출력 파일을 가져올 수 있다고 리듀서에게 알려줍니다.
  - 리듀서를 기준으로 파티셔닝하고 정렬한 뒤 매퍼에게 데이터 파티션을 복사하는 과정을 **셔플(shuffle)** 라고 합니다.
- 리듀서 태스크는 매퍼로부터 파일을 가져와 정렬된 순서를 유지하면서 병합합니다. (그래서 리듀서의 입력으로 들어갈 때는 서로 인전해서 들어가게 됩니다.)
- 리듀서는 키와 반복자(iterator)를 인자로 호출하는 데 이 반복자로 전달된 키와 동일한 키를 가진 레코드를 모두 훑을 수 있습니다.

#### 맵리듀스 워크플로

- 맵리듀스 작업 하나로 해결할 수 있는 문제의 범위는 제한적입니다.
- 즉, 맵리듀스 작업을 연결해 **워크폴로(workflow)** 로 구성하는 방식이 꽤 일반적입니다.
- 일괄 처리 작업의 출력은 작업이 성공적으로 끝났을 때만 유효합니다. (맵리듀스는 작업이 실패하고 남은 부분 출력은 제거합니다.)
- 이런 스케줄러에는 많은 일괄 처리 작업의 집합을 유지보수할 때 유용한 관리 기능이 있습니다.

### 리듀스 사이드 조인과 그룹화

- 여러 데이터넷에서 한 레코드가 다른 레코드와 연관이 있는 것은 일반적입니다.
  - 관계형 모델에서는 **외래키(foreign key),** 문서 모델에서는 **문서 참조(document reference),** 그래프 모델에서는 **간선(edge)** 라고 합니다.
- 연관된 레코드 양쪽 모두에 접근해야 하는 코드가 있다면 조인은 필수적입니다.
- 데이터베이스에서 적은 수의 레코드만 관련된 질의를 실행한다면 데이터베이스는 일반적으로 색인(index)을 사용합니다.
  - 그러나, 맵리듀스에서는 색인 개념이 없습니다.
- 맵리듀스는 파일을 전체 읽으며 (데이터베이스에는 이 연산을 전체 테이블 스캔, **full table scan**), 이는 비용이 비싸보이지만 병렬처리가 가능하기 대문에 합리적입니다.
- 일괄 처리 맥락에서의 조인은 **데이터셋 내 모든 연관 관계를 다룬다는 뜻**입니다.

#### 사용자 활동 이벤트 분석 예제

- 일괄 처리에서는 이벤트 로그(**활동 이벤트(activity event)** 또는 클릭스트림 **데이터(clickstream data)** )고 오른쪽은 사용자 데이터베이스입니다.
- 그러나 이러한 처리에서 사용자 데이터베이스가 원격에 있으면 나쁜 성능이 됩니다.
- 일괄 처리에서는 처리량을 높이기 위해서는 가능한 한 장비에서 연산을 수행해야 하므로, **데이터베이스의 사본을 가져와 사용자 활동 이벤트 로그가 저장된 분산 파일 시스템에 넣는 것**이 좋습니다.

#### 정렬 병합 조인

- 매퍼는 입력 레코드로부터 키와 값을 추출하는 것이 목적입니다.

![리듀스 측 정렬 병합 조인](https://user-images.githubusercontent.com/42582516/143947889-4300e29c-fa1e-43d4-988b-729dc26652e8.png)

- 맵리듀스 프레임워크에서 키로 매퍼의 출력을 파티셔닝해 키-값 쌍으로 정렬한다면 같은 사용자의 활동 이벤트와 사용자 레코드는 리듀서의 입력으로 서로 인접해서 들어갑니다.
- 리듀서가 항상 사용자 데이터베이스를 먼저 보고 활동 이벤트를 시간 순으로 보게 하는 식으로 맵리듀스에서 작업 레코드를 재배열하기도 합니다. 이를 **보조 정렬(secondary sort)** 라고 합니다.
- 보조 정렬후, 리듀서 함수는 모든 사용자 ID당 한번만 호출되고 보조 정렬 덕분에 첫 번째 값은 사용자 데이터베이스의 생년월일 레코드로 예상할 수 있습니다.
  - 리듀서는 본 **URL(viewed-url)** 과 **본 사람의 연령의 쌍**을 출력합니다.
  - 이를 통해 각 URL마다 본 사람의 연령 분호를 계산하고 연령대별로 클러스터링할 수 있습니다.
- 리듀서는 특정 사용자 ID의 모든 레코드를 한 번에 처리하므로 한 번에 사용자 한 명의 레코드만 메모리에 유지하면 되고 네트워크로 아무 요청도 보낼 필요가 없스빈다. 이를 **정렬 병합 조인(sort-merge join)** 이라고 합니다.
  - 매퍼 출력이 키로 정렬된 후에 리듀서가 조인의 양측의 정렬된 레코드 목록을 병합합니다.

#### 같은 곳으로 연관된 데이터 가져오기

- 병합 정렬 조인 중 매퍼와 정렬 프로세스는 특정 사용자 ID로 조인 연산을 할 때 필요한 모든 데이터베이스를 한 곳으로 모읍니다.
  - 필요한 데이터를 사전에 줄을 세웠기 때문에 단 리듀서는 단일 스레드로 동작하는 간단한 코드 조각이 될 수 있으며 레코드를 휘젓고 다닐 때 처리량은 높게 유지하면ㄷ서 메모리 부담을 줄일 수 있습니다.
- 같은 키를 가진 키-값 쌍은 같은 리듀서를 호출합니다.
- 맵리듀스 프로그래밍 모델은 올바른 장비로 **데이터를 모으는 연산**의 물리적 네트워크 통신 측면과 받은 **데이터를 처리하는 애플리케이션 로직을 분리**합니다.
  - 이는 데이터베이스 사용 유형과 대조적입니다.
  - 맵리듀스는 애플리케이션 로직에서 영향이 가지 않게 실패한 태스크는 확실하게 재시도합니다.

#### 그룹화

- 조인 외에도 "같은 곳으로 관련 데이터를 모으는" 일반적인 사용 유형은 SQL에서 `GROUP BY` 절과 같이 특정 키로 레코드를 그룹화하는 것입니다.
- 맵리듀스로 그룹화 연산을 구현하는 가장 간단한 방법은 매퍼가 키-값 쌍을 생성할 때 그룹화할 대상을 키로 하는 것입니다.
  - 맵리듀스 위에서 그룹화와 조인의 구현은 상당히 유사합니다.
- 특정 사용자가 취한 일련의 활동을 찾기 위해 사용자 세션별 활동 이벤트를 수집 분석할 때도 일반적으로 그룹화를 사용합니다. 이 과정을 **세션화(sessionization)** 이라고 합니다.
- 사용자 요청을 받는 웹 서버가 여러 개라면 특정 사용자의 활동 이벤트는 여러 서버로 분산돼 각각 다른 로그 파일에 저장됩니다.
  - 세션 쿠키, 사용자 ID나 유사한 식별자를 그룹화 키로 사용해 특정 사용자 활동 이벤트를 모두 한 곳으로 모으면 세션화를 구현할 수 있습니다.
  - 이때 서로 다른 사용자의 이벤트는 다른 파티션으로 골고루 분산됩니다.

#### 쏠림 다루기

- 키 하나에 너무 많은 데이터가 연관된다면 (ex. 소셜 네트워크) 불균형한 활성 데이터베이스 레코드를 가지게 되는데 이를 **린치핀 객체(linchpin object)** 또는 **핫 키(hot key)** 라고 합니다.
- 유명 인사 한 사람에 관련된 모든 활동을 리듀서 한 개에서 모은다면 상당한 쏠림 현상이 생깁니다. 이 현상을 **핫스팟**이라고 합니다.
  - 즉, 한 리듀서가 다른 리듀서보다 엄청나게 많은 레코드를 처리해야 합니다.
- 조인 입력에 핫 키가 존재하는 경우 핫스팟을 완화시킬 몇 가지 알고리즘이 있습니다.
  - **쏠린 조인(skewed join) 메서드**는 어떤 키가 핫 키인지 결정하기 위해 샘플링 작업을 수행합니다. 이 경우 핫키로 조인할 다른 입력은 핫 키가 전송된 모든 리듀서에 복제합니다.
  - **공유 조인(shared join) 메서드**는 이 기법과 비슷하나 핫 키를 명시적으로 지정합니다.
- 핫 키로 레코드를 그룹화하고 집계하는 작업은 두 단계로 수행됩니다.
  - 첫 번째 맵리듀스 단게는 레코드를 임의의 리듀서로 보냅니다. 각 리듀서는 핫 키 레코드의 일부를 그룹화하고 키별로 집계해 간소화한 값을 출력합니다.
  - 두 번째 맵리듀스 작업은 첫 단계 모든 리듀서에서 나온 값을 키별로 모두 결합해 하나의 값으로 만듭니다.

---

> Map Reducer 구현, 파이썬

단어 빈도수 세기 예제

```python
"""mapper.py"""

import sys

for line in sys.stdin:
    line = line.strip()
    words = line.split()
    for word in words :
        print ('%s\t%s' % (word, 1))
```

```python
"""reducer.py"""

from operator import itemgetter
import sys

current_word = None
current_count = 0
word = None

for line in sys.stdin:
    line = line.strip()
    word, count = line.split('\t', 1)

    try:
        count = int(count)
    except ValueError:
        continue

    if current_word == word:
        current_count += count
    else:
        if current_word:
            print('%s\t%s' % (current_word, current_count))
        current_count = count
        current_word = word

if current_word == word:
    print('%s\t%s' % (current_word, current_count))
```

- mapper의 아웃풋을 '키'인 단어 기준으로 정렬

```shell
cat hadoop.txt | python mapper.py | sort -k 1
```

- 아웃풋을 reducer로 전달한후, 내림차순으로 정리한 경우

```shell
cat hadoop.txt | python mapper.py | sort -k 1 | python reducer.py | sort -k 2
```

[참고 링크](https://3months.tistory.com/521)

### 맵 사이드 조인

- 앞의 여러 조인 알고리즘은 실제 조인 로직을 리듀서에서 수행하기 때문에 **리듀스 사이드 조인(reduce-side join)** 이라고 합니다.
- 매퍼는 입력 데이터를 준비하는 역할을 합니다.
- 리듀스 사이드 접근법의 장점은 이벽 데이터에 대한 특정 가정이 필요없다는 점입니다.
  - 그러나 정렬 후 리듀서로 복사한 뒤 리듀서 입력을 병합하는 모든 과정에 비용이 상당한 단점이 있습니다.
- 입력 데이터에 대해 특정 가정이 **가능**하다면 **맵사이드 조인(map-side join)** 으로 불리는 기법을 사용해 조인을 더 빠르게 수행할 수 있습니다.

#### 브로드캐스트 해시 조인

- 맵 사이드 조인은 작은 데이터셋과 매우 큰 데이터셋을 조인하는 경우에 간단하게 적용가능합니다
  - 작은 데이터셋은 전체를 각 매퍼 메모리에 적재 가능할 정도로 충분히 작아야 합니다.
  - 이러한 매퍼 태스크를 여러개 사용할 수도 있습니다.
- 위처럼 간단하고 효율적인 알고리즘으을 **브로드캐스트 해시 조인(broadcast hash join)** 이라 합니다.
  - **브로드캐스트**라는 단어는 큰 입력의 파티션 하나를 담당하는 각 매퍼는 작은 입력 전체를 읽는다는 것입니다.
  - 해시라는 이름에서 알 수 있듯이, 해시 테이블을 사용합니다.
- 작은 조인 입력을 인메모리 해시 테이블로 적재하는 대신 로컬 디스크에 읽기 전용 색인으로 작은 조인 입력을 저장하기도 합니다.
  - 즉,이 방법을 사용하면 데이터셋 전체가 메모리 안에 들어오지 않더라도 거의 인메모리 해시 테이블만큼 빠르게 임의 접근 조회가 가능합니다.

#### 파티션 해시 조인

- 같은 방식으로 맵 사이드 조인의 입력을 파티셔닝한다면 해시 조인 접근법을 각 파티션에 독립적으로 적용할 수 있습니다.
- 제대로 파티셔닝이 작동했다면 조인할 레코드 모두가 같은 번호의 파티션에 위치합니다.
  - 각 매퍼는 각 입력 데이터셋 중 파티션 한 개만 읽어도 충분합니다. 이러한 방법은 각 매퍼의 해시 테이블에 적재해야 할 데이터의 양을 줄일 수 있다는 점이 장점입니다.
- 파티션 해시 조인은 조인할 두 입력 모두를 같은 키와 같은 해시 함수를 기반으로 같은 수로 파티셔닝해야 작동합니다.
- 파티션 해시 조인(partitioned hash join)을 하이브에서는 **버킷 맵 조인(bucketed map join)** 이라고 합니다.

#### 맵 사이드 병합 조인

- 입력 데이터셋이 같은 방식으로 파티셔닝됐을 뿐 아니라 같은 키를 기준으로 **정렬**됐다면 변형된 맵 사이드 조인을 적용할 수 있습니다.
- 맵 사이드 병합 정렬(map-side merge join)이 가능하다면 선행 맵리듀스 작업이 이미 입력 데이터셋을 파티셔닝하고 정렬해 놓았다는 뜻입니다.

#### 맵 사이드 조인을 사용하는 맵리듀스 워크플로

- 맵리듀스 조인의 출력을 하위 작업에서 입력으로 사용하거나, 맴 사이드 조인을 사용하거나, 리듀스 사이드 조인을 사용할지에 따라 그 출력 구조가 달라집니다.
  - 리듀스 사이드 조인은 조인 키로 파티셔닝하고 정렬해서 출력하빈다.
  - 반면 맵 사이드 조인은 큰 입력과 동일한 방법으로 파티셔닝하고 정렬합니다.
- 맵 사이드 조인을 수행하기 위해서는 크기, 정렬, 입력 데이터의 파티셔닝 같은 제약 사항이 따릅니다.
  - 조인 전략을 최적화할 때는 물리적 레이아웃(파티션 수, 데이터가 어떤 키를 기준으로 파티셔닝되고 정렬됐는지) 파악이 중요합니다.
- 하둡 생태계에서는 데이터셋 파티셔닝 관련 메타데이터를 관리하는데 H카탈로그(HCatalog)나 하이브(Hive) 메타스토어를 사용하기도 합니다.

### 일괄 처리 워크플로의 출력

### 하둡과 분산 데이터베이스의 비교

<br/>

## 맵리듀스를 넘어

### 중간 상태 구체화

### 그래프와 반복 처리

### 고수준 API와 언어

<br/>

## 정리
