---
sidebar_position: 11
---

# 11. 스트림 처리

- 10장에서는 일괄처리에 대해 설명했습니다.
  - 일괄처리란 입력으로 파일 집합을 읽어 출력으로 새로운 파일 집합을 생성하는 기술
  - 그러나, 입력을 사전에 알려진 유한한 크기로 한정한다는 중요한 가정이 있습니다.
- 현실에서는 많은 데이터가 시간에 따라 도착하기 때문에 한정적이지 않습니다.
- 일간 일괄 처리의 문제점은 입력의 변화가 하루가 지나야 반영됩니다.
  - 따라서 고정된 시간 조각이라는 개념을 완전히 버리고 단순히 이벤트가 발생할 때마다 처리해야 합니다. 이가 **스트림 처리**의 기본 개념입니다.

아래에서는 데이터 관리 메커니즘으로 **이벤트 스트림**을 설명합니다.

## 이벤트 스트림 전송

- 스트림 처리 문맥에서 레코드는 보통 이벤트라고 하지만 특정 시점에 일어난 사건에 대한 세부 사항을 포함하는, 작고 독립된 불변 객체라는 점에서 본질적으로 동일합니다.
- 일괄 처리에서 한 번 기록하면 여러 작업에서 읽을 수 있습니다. 스트리밍에서도 이와 비슷합니다.
  - **생산자(producer)**가 이벤트를 한 번 만들면 해당 이벤트를 복수의 소비자(consumer, 구독자(subscriber) 또는 수신자(recipient))가 처리할 수 있습니다.
  - 파일 시스템에서는 관련 레코드 집합을 파일 이름으로 식별하지만 스트림 시스템에서는 대개 **토픽(topic)** 이나 **스트림**으로 관련 이벤트를 묶습니다.
- 이론상으로는 파일이나 데이터베이스가 있으면 생산자와 소비자를 연결하기는 충분하며지만, 지연 시간이 낮으면서 지속해서 처리하는 방식을 지향할 때 데이터스토어를 이런 용도에 맞게 설계하지 않았다면 폴링 방식은 비용이 큽니다.
- 데이터베이스는 전통적으로 알림 메커니즘을 강력하게 지원하지 않습니다.
  - 관계형 데이터베이스에서는 보통 트리거(trigger) 기능이 있습니다.
  - 그러나 트리거는 기능이 제한적이고 데이터베이스를 설계한 이후에 도입된 개념이며, 이벤트 알림 전달 목적으로 개발된 도구는 따로 있습니다.

### 메시징 시스템

- 새로운 이벤트에 대해 소비자에게 알려주려고 쓰이는 일반적인 방법은 **메시징 시스템(messaging system)** 을 사용하는 것입니다.
  - 생산자는 이벤트를 포함한 메시지를 전송하고, 메시지는 소비자에게 전달됩니다.
- 메시징 시스템을 구축하는 가장 간단한 방법은 생산자와 소비자 사이에 유닉스 파이프나 TCP 연결과 같은 직접 통신 채널을 사용하는 방법입니다.
- **발행/구독(publish/subscribe)** 모델에서는 여러 시스템들이 다양한 접근법을 사용합니다. 아래 두 질문이 이 시스템을 구별하는데 상당히 도움이 됩니다.
  - 생산자가 소비자가 메시지를 처리하는 속도보다 빠르게 메시지를 전송한다면 어떻게 될지?
    - 세가지 선택지인 메시지를 버리거나, 큐에 메시지를 버퍼링하거나, 생산자를 적용합니다.
  - 노드가 죽거나 일시적으로 오프라인이 된다면 어떻게 될까? 손실되는 메시지가 있을까?
    - 디스크에 기록하거나 복제본 생성을 하거나, 둘 모두를 해야합니다.
- 메시지의 유실을 허용할지 말지는 애플리케이션에 따라 상당히 다릅니다.

#### 생산자에서 소비자로 메시지를 직접 전달하기

- 많은 메시지 시스템은 중간 노드를 통하지 않고 생산자와 소비자를 네트워크로 직접 통신합니다.
  - UDP 멀티캐스트는 낮은 지연이 필수인 주식 시장과 같은 금융 산업에서 널리 사용됩니다.
  - ZeroMQ 같은 브로커가 필요없는 메시징 라이브러리는 TCP 또는 IP 멀티캐스팅 상에서 발행/구독 메시징을 구현합니다.
  - StatsD과 BruBeck은 네트워크 상의 모든 장비로부터 지표를 수집하고 모니터링하고 UDP 메시징을 사용합니다.
  - 소비자가 네트워크에 서비스를 노출하면 생산자는 HTTP나 RPC 요청을 직접 보낼 수 있습니다.
- 직접 메시징 시스템은 설계 상호아에서는 잘동작하지만 일반적으로 메시지가 유실될 수 있는 가능성을 고려해서 애플리케이션 코드를 작성해야 합니다.
  - 즉, 직접 메시징 시스템은 일반적으로 생산자와 소비자가 항상 온라인 상태라고 가정합니다.
- 소비자가 오프라인이라면 메시지를 전달하지 못하는 상태에 있는 동안 전송된 메시지는 잃어버릴 수 있습니다.
  - 일부 프로토콜은 실패한 메시지 전송을 생산자가 재시도하게끔 하지만 생산자 장비가 죽어버리면 재시도하려고 했던 메시지 버퍼를 잃어버릴 수 있기 때문에 문제가 있습니다.

#### 메시지 브로커

- 직접 메시징 시스템의 대안으로 널리 사용되는 방법은 **메시지 브로커(메시지 큐)** 를 통해 메시지를 보내는 것입니다.
  - 메시지 브로커는 근본적으로 메시지 스트림를 처리하는 데 최적화된 데이터베이스의 일종입니다.
- 브로커에 데이터가 모이기 때문에 이 시스템은 클라이언트의 상태 변경(접속, 접속 해제, 장애)에 쉽게 대처할 수 있습니다.
  - 지속성 문제가 생산자와 소비자에서 브로커로 옮겨갔기 때문입니다.
- 큐 대기를 하면 소비자는 일반적으로 **비동기**로 동작합니다.
  - 생산자가 메시지를 보낼 때 생산자는 브로커가 해당 메시지를 버퍼에 넣었는지만 확인하고 소비자가 메시지를 처리하기까지 기다리지 않습니다.
  - 메시지를 소비자로 배달하는 것은 정해지지 않은 미래 시점이지만 때로는 큐에 백로그가 있다면 상당히 늦을 수 있습니다.

#### 메시지 브로커와 데이터베이스의 비교

- 어떤 메시지 브로커는 XA 또는 JTA를 이용해 2단계 커밋을 수행하기도 합니다. 메시지 브로커와 데이터베이스에는 중요한 실용적 차이가 있지만 이 특징은 데이터베이스의 속성과 상당히 비슷합니다.
  - 데이터베이스는 명시적으로 데이터 삭제될 때까지 데이터를 보관합니다. 반면 메시지 브로커 대부분은 소비자에게 데이터 배달이 성공할 경우 자동으로 메시지를 삭제합니다.
  - 메시지 브로커는 대부분 메시지를 빨리 지우기 때문에 작업 집합이 상당히 작다고 가정합니다. 즉 큐 크기가 작습니다.
  - 데이터베이스는 보조 색인을 지원하고 데이터 검색을 위한 다양한 방법을 지원하는 반면 메시지 브로커는 특정 패턴과 부합하는 토픽의 부분 집합을 구독하는 방식을 지원합니다.
  - 데이터베이스에 질의할 때 그 결과는 일반적으로 질의 시점의 데이터 스냅숏을 기준으로 합니다.

#### 복수 소비자

- 복수 소비자가 같은 토픽에서 메시지를 읽을 때 사용하는 주요 패턴은 두가지입니다.
  - **로드밸런싱**
    - 각 메시지는 소비자 중 하나로 전달됩니다. 따라서 소비자들은 해당 토픽의 메시지를 처리하는 작업을 공유합니다.
    - 브로커는 메시지를 전달할 소비자를 임의로 지정합니다.
  - **팬 아웃**
    - 각 메시지는 **모든** 소비자에게 전달됩니다.
- 이 두가지 패턴은 함께 사용 가능합니다.

#### 확인 응답과 재전송

- 소비자들은 언제라도 장애가 발생할 수 있습니다.
  - 메시지를 잃어버리지 않기 위해 메시지 브로커는 **확인 응답**을 사용합니다.
- 브로커가 확인 응답을 받기 전에 클라이언트로의 연결이 닫히거나 타임아웃되면 브로커는 메시지가 처리되지 않았다고 가정하고 다른 소비자에게 다시 전송합니다.
- 부하 균형 분산과 결합할 때 이런 재전송 행위는 메시지 순서에 영향을 미치게 됩니다.
- 메시지 브로커는 JMS와 AMQP 표준에서 요구하는 대로 메시지 순서를 유지하려 노력할지라도 부하 균형 분산과 메시지 재전송을 조합하면 필연적으로 메시지 순서가 변경됩니다.
  - 그러나, 부하 균형 분산 기능을 사용하지 않는다면 이 문제를 피할 수 있습니다.

### 파티셔닝된 로그

- 네트워크 상에서 패킷을 전송하거나 네트워크 서비스에 요청하는 작업은 보통 영구적 추적을 남기지 않는 일시적 연산입니다.
  - 메시지 브로커가 메시지를 디스커에 지속성 있게 기록하더라도 메시지가 소비자에게 전달된 후 즉시 삭제합니다.
- 데이터베이스와 파일 시스템의 접근법은 이와 반대입니다.
  - 일반적으로 데이터베이스나 파일ㄹ에 저장하는 모든 데이터는 적어도 누군가 명시적으로 다시 삭제할 때까지는 영구적으로 보관된다고 간주합니다.
- 개념의 차이는 파생 데이터를 생성하는 방식에 큰 영향을 미칩니다.
- 메시징 시스템에 새로운 소비자를 추가하면 일반적으로 소비자를 등록한 시점 이후에 전송된 메시지부터 받기 시작합니다.
- 데이터베이스의 지속성 있는 저장 방법과 메시징 시스템의 지연 시간이 짧은 알림 기능을 조합한 것이 **로그 기반 메시지 브로커(log-based message broker)** 입니다.

#### 로그를 사용한 메시지 저장소

- 로그는 단순히 디스크에 저장된 추가 전용 레코드의 연속입ㄴ티다.
- 브로커를 구현할 때도 생산자가 보낸 메시지는 로그 끝에 추가하고 소비자는 로그를 순차적으로 읽어 메시지를 받습니다.
- 디스크 하나를 쓸 때보다 처리량을 높이기 위해 확장하는 방법으로 로그를 **파티셔닝** 하는 방법이 있습니다.
  - 다른 파티션은 다른 장비에서 서비스할 수 있습니다.
- 각 파티션 내에서 브로커는 모든 메시지에 **오프셋**이라고 부르는, 단조 증가하는 순번을 부여합니다.
  - 파티션이 추가 전용이고 따라서 파티션 내 전체 메시지는 전체 순서가 있기 때문에 순번을 부여하는 것은 타당합니다.
  - 단 다른 파티션 간 메시지의 순서는 보장하지 않습니다.

![생산자가 메시지를 전송하면 메시지는 토픽 파티션 파일에 추가](https://user-images.githubusercontent.com/42582516/145231765-b24869a6-3658-4287-a2dc-3e79591f857d.png)

- 아파치 카프카(Apache Kafka), 아마존 키네시스 스트림(Amazon Kinesis Stream), 트위터의 분산 로그(DistributedLog)가 이런 방식으로 동작하는 로그 기반 메시지 브로커입니다.
  - 구글 클라우드 Pub/Sub은 아키텍처는 비슷하지만 노출된 API는 로그 추상화가 아닌 JMS 형식입니다.
  - 이런 메시지 브로커는 모든 메시지를 디스크에 저장하지만 여러 장비에 메시지를 파티셔닝해 초당 수백만 개의 메시지를 처리할 수 있고 메시지를 복제함으로써 **장애에 대비**할 수 있습니다.

#### 로그 방식과 전통적인 메시징 방식의 비교

- 로그 기반 접근법은 당연히 팬 아웃 메시징 방식을 제공합니다.
  - 소비자가 서로 영향 없이 독립적으로 로그를 읽을 수 있고 메시지를 읽어도 로그에서 삭제되지 않기 때문입니다.
  - 개별 메시지를 소비자 클라이언트에게 할당하지 않고 소비자 그룹 간 로드밸런싱하기 위해 브로커는 소비자 그룹의 노드들에게 전체 파티션을 할당할 수 있습니다.
- 각 클라이언트는 할당된 파티션의 메시지를 **모두** 소비합니다.
  - 일반적으로 소비자에 로그 파티션이 할당되면 소비자는 단일 스레드로 파티션에서 순차적으로 메시지를 읽습니다.
  - 이러한 거친 방식의 로드밸런싱 방법은 몇 가지 불리한 면이 있습니다.
    - 토픽 하나를 소비하는 작업을 공유하는 노드 수는 많아야 해당 토픽의 로그 파티션 수로 제한됩니다. 같은 파티션 내 메시지는 같은 노드로 전달되기 때문입니다.
    - 특정 메시지 처리3가 느리면 파티션 내 후속 메시지 처리가 지연됩니다
- 즉, 메시지를 처리하는 비용이 비싸고 메시지 단위로 병렬화 처리하고 싶지만 메시지 순서는 그렇게 중요하지 않다면 **JMS/AMQP 방식의 메시지 브로커가 적합**합니다.
  - 반면 처리량이 많고 메시지를 처리하는 속도가 빠르지만 메시지 순서가 중요하다면 로그 기반 접근법이 효과적입니다.

#### 소비자 오프셋

- 파티션 하나를 순서대로 처리하면 메시지를 어디까지 처리했는지는 알기 쉽습니다.
  - 브로커는 모든 개별 메시지마다 보내는 확인 응답을 추적할 필요가 없습니다.
- 메시지 오프셋은 단일 리더 데이터베이스 복제에서 널리 쓰는 **로그 순차 번호(log sequence number)** 와 상당히 유사합니다.
  - 데이터베이스 복제에서 팔로워가 리더와 연결이 끊어졌다가 다시 접속할 때 로그 순차 번호를 사용합니다.
- 소비자 노드에 장애가 발생하면 소비자 그룹 내 다른 노드에 장애가 발생한 소비자의 파티션을 할당하고 마지막 기록된 오프셋부터 메시지를 처리하기 시작합니다.
  - 장애가 발생한 소비자가 처리했지만 아직 오프셋을 기록하지 못한 메시지가 있다면 이 메시지는 두 번 처리되는 문제가 있습니다.

#### 디스크 공간 사용

- 로그를 계속 추가한다면 결국 디스크 공간을 전부 사용하게 됩니다.
  - 디스크 공간을 재사용하기 위해 실제로는 로그를 여러 조각으로 나누고 가끔 오래된 조각을 삭제하거나 보관 저장소로 이동합니다.
- 소비자가 처리 속도가 느려 메시지가 생산되는 속도를 따라잡지 못하면 소비자가 너무 뒤처져 소비자 오프셋이 이미 삭제한 조각을 가리킬 수 도 있습니다.
  - 즉 메시지 일부를 잃어버릴 가능성이 있습니다.
  - 결과적으로 로그는 크기가 제한된 버퍼로 구현하고 버퍼가 가득차면 오래된 메시지 순서대로 버립니다.
    - 이러한 버퍼를 **원형 버퍼(circular buffer)** 또는 **링 버퍼(ring buffer)** 라고 합니다.
- 메시지 보관 기간과 관계없이 모든 메시지를 디스크에 기록하기 때문에 로그 처리량은 일정합니다.
  - 이러한 동작은 기본적으로 메모리에 메시지를 유지하고 큐가 너무 커질 때만 디스크에 기록하는 메시징 시스템과는 반대입니다.

#### 소비자가 생산자를 따라갈 수 없을 때

- 소비자가 메시지를 전송하는 생산자를 따라갈 수 없을 때 선택할 수 있는 선택지 세 가지가 있습니다.
  - 메시지 버리기, 버퍼링, 배압 적용하기
  - 로그 기반 접근법을 이 방식으로 분류하자면 대용량이지만 고정 크기의 버퍼를 사용하는 버퍼링 형태입니다.
- 소비자가 뒤처져 필요한 메시지가 디스크에 보유한 메시지보다 오래되면 필요한 메시지는 읽을 수 없습니다.
  - 그래서 브로커는 버퍼 크기를 넘는 오래된 메시지를 자연스럽게 버립니다.
- 어떤 소비자가 너무 뒤처져서 메시지를 읽기 시작해도 해당 소비자만 영향을 받고 다른 소비자들의 서비스를 망치지는 않습니다. 이는 **운영상 상당한 장점**입니다.
- 전통적인 메시지 브로커와 대조적입니다. 전통적 메시지 브로커는 소비자가 중단되면 그 소비자가 사용하던 큐를 삭제해줍니다. 그렇지 않으면 메모리를 계속 뺏기게 됩니다.

#### 오래된 메시지 재생

- AMQP와 JMS 유형의 메시지 브로커에서 메시지를 처리하고 확인 응답하는 작업은 브로커에서 메시지를 제거하기 때문에 파괴적 연산입니다. 반면 로그 기반 메시지 브로커는 메시지를 소비하는 게 오히려 파일을 읽는 작업과 더 유사한데 로그를 변화시키지 않는 읽기 전용 연산이기 때문이빈다.
- 소비자의 출력을 제외한, 메시지 처리의 유일한 부수 효과는 소비자 오프셋 이동입니다.
  - 이는 필요하다면 쉽게 조작할 수 있습니다.
- 위 점은 일괄 처리와 유사한 측면입니다.
  - 로그 기반 메시징과 일괄 처리는 변환 처리를 반복해도 입력 데이터에 영향을 전혀 주지 않고 파생 데이터를 만듭니다.
  - 로그 기반 메시징 시스템은 많은 실험을 할 수 있고 오류와 버그를 복구하기 쉽기 때문에 조직 내에서 데이터플로를 통합하는데 좋은 도구입니다.

<br/>

## 데이터베이스와 스트림

- 브로커와 데이터베이스는 전통적으로 전혀 다른 범주의 도구로 생각되지만 로그 기반 브로커는 데이터베이스에서 아이디어를 얻어 시징에 적용할 수 있으며 이 반대도 가능합니다. 즉, 메시징과 스트림에서 아이디어를 가져와 데이터베이스에 적용할 수 있습니다.
- 이벤트는 특정 시점에 발생한 사건을 기록한 레코드입니다.
  - 사건은 측정 판독일 수도 있지만 **데이터베이스에 기록**하는 것일 수 도 있습니다.
  - 데이터베이스와 스트림 사이의 연결점이 단지 디스크에 로그를 저장하는 물리적 저장소 이상입니다.
- 복제 로그는 데이터베이스 기록 이벤트의 스트림입니다.
  - 데이터베이스가 트랜잭션을 처리할 때 리더는 데이터베이스 기록 이벤트를 생산합니다.

### 시스템 동기화 유지하기

- 이 책에서 데이터 저장과 질의, 처리 요구사항을 모두 만족하는 단일 시스템은 없습니다.
  - 실제로 대부분의 중요 애플리케이션이 요구사항을 만족하기 위해 몇 가지 다른 기술의 조합이 필요합니다.
  - 사용자 요청에 대응하기 위한 OLTP 데이터베이스, 공통 요청의 응답 속도를 높이기 위한 캐시, 검색 질의를 다루기 위한 전문 색인, 분석용 데이터 웨어하우스가 그 예시입니다.
  - 이 시스템은 각각은 데이터의 복제본을 가지고 있고 그 데이터는 목적에 맞게 최적화된 형태로 각각 저장됩니다.
- 관련이 있거나 동일한 데이터가 여러 다른 장소에서 나타나기 때문에 서로 동기화가 필 수 입니다.
  - 일반적으로 데이터 웨어하우스는 벌크 로드합니다.
- 주기적으로 데이터베이스 전체를 덤프하는 작업이 너무 느리면 대안으로 사용하는 방법으로 **이중 기록(dual write)** 가 있습니다.
  - 이중 기록을 사용하면 데이터가 변할 때마다 애플리케이션 코드에서 명시적으로 각 시스템에 기록합니다.
- 이중 기록은 몇가지 심각한 문제가 있으며, 대표적인 예시로 경쟁 조건이 있습니다.

![경쟁조건 시 문제](https://user-images.githubusercontent.com/42582516/145303392-6a396195-4528-494d-8c61-e4f19a93ca5f.png)

- 이중 쓰기의 다른 문제는 한쪽 쓰기가 성공할 때 다른 쪽 쓰기는 실패할 수 있다는 점입니다.

### 변경 데이터 캡처

- 최근 들어 **변경 데이터 캡처(change data capture, CDC)** 에 관심이 높아지고 잇습니다.
  - 변경 데이터 캡처는 데이터베이스에 기록하는 모든 데이터의 변화를 관찰해 다른 시스템으로 데이터블을 복제할 수 있는 형태로 추출화는 과정입니다.

#### 변경 데이터 캡처의 구현

- 검색 색인과 데이터 웨어하우스에 저장된 데이터는 레코드 시스템에 저장된 데이터의 또 다른 뷰일 뿐이므로 로그 소비자를 **파생 데이터 시스템**이라 할 수 있습니다.
- 변경 데이터 캡처는 본질적으로 변경 사항을 캡처할 데이터베이스 하나를 리더로 하고 나머지를 팔로워로 합니다.
  - 로그 기반 메시지 브로커는메시지 순서를 유지하기 때문에 원본 데이터베이스에서 변경 이벤트를 전송하기에 적합합니다.
- 변경 데이터 캡처를 구현하는데 데이터베이스 트리거를 사용하기도 합니다.
  - 데이터 테이블의 모든 변화를 관찰하는 트리거를 등록하고 변경 로그 테이블에 해당 항목을 추가하는 방식입니다.
  - 이 방식은 고장나기 쉽고 성능 오버헤드가 상당합니다.
- 변경 데이터 캡처는 메시지 브로커와 동일하게 비동식 방식으로 동작합니다.
  - 운영상 이점이 있는 설계로 느린 소비자가 추가되도 레코드 시스템에 미치는 영향이 적습니다. 그러나, 복제 지연의 모든 문제가 발생하는 단점이 있습니다.

#### 초기 스냅숏

- 데이터베이스에서 발생한 모든 변경 로그가 있다면 로그를 재현해서 데이터베이스의 전체 상태를 재구축할 수 있습니다.
  - 그러나 대부분 모든 변경 사항을 영구적으로 보관하는 일은 디스크 공간이 너무 많이 필요하고 모든 로그를 재생하는 작업도 너무 오래 걸립니다. 즉, 로그를 적당히 잘라야 합니다.
  - 전문 색인은 예시로 들면, 전체 데이터베이스 복사본이 필요합니다. (스냅숏을 사용)
- 데이터베이스 스냅숏은 변경 로그의 위치나 오프셋에 대응돼야 합니다.
  - 이를 통해 이후에 변경 사항을 적용할 시점을 알 수 잇습니다.

#### 로그 컴팩션

- **로그 컴팩션(log compaction)** 은 **주기적으로 같은 키의 로그 레코드를 찾아 중복을 제거하고 각 키에 대해 가장 최근에 갱신된 내용만 유지**합니다.
  - 컴팩션과 병합 과정은 백그라운드로 실행됩니다.
- 로그 구조화 저장 엔진에서 **특별한 널 값(톰스톤, tombstone)** 으로 갱신하는 것은 키의 삭제를 의미하고 로그 컴팩션을 수행할 때 실제로 값을 제거합니다.
  - 툼스톤은 키를 덮어쓰거나 삭제하지 않는 한 영구적으로 유지됩니다.
  - 로그 기반 메시지 브로커와 데이터 캡처에서도 이를 적용할 수 있습니다.
- **아파치 카프카**는 로그 컴팩션 기능을 제공합니다.

#### 변경 스트림용 API 지원

- 최근 데이터베이스들은 기능 개선이나 리버스 엔지니어링을 통해 CDC 지원을 하기보다 점진적으로 변경 스트림을 기본 인터페이스로서 지원하기 시작했습니다.
- 카프카 커넥트(Kafka Connect)는 카프카를 광범위한 데이터 시스템용 변경 데이터 캡처 도구로 활용하기 위한 노력의 일환입니다.
  - 변경 이벤트를 스트림하는 데 카프카를 사용하면 검색 색인과 같은 파생 데이터 시스템을 갱신하는데 사용 가능하고 이번 장 후반부에 설명할 스트림 처리 시스템에도 이벤트 공금이 가능합니다.

### 이벤트 소싱

### 상태와 스트림 그리고 불변성

<br/>

## 스트림 처리

### 스트림 처리의 사용

### 시간에 관한 추론

### 스트림 조인

### 내결함성

<br/>

## 정리
